{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678baa34",
   "metadata": {},
   "source": [
    "# SEO Content Detector: End-to-End Pipeline\n",
    "This notebook builds a full pipeline to parse HTML, engineer NLP features, detect duplicates, and train a content quality model. It also exposes a real-time `analyze_url(url)` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce6372",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537b670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "import pandas as pd, numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "try:\n",
    "    import textstat\n",
    "except Exception as e:\n",
    "    textstat = None\n",
    "    \n",
    "cwd = os.path.abspath(os.getcwd())\n",
    "if os.path.basename(cwd) == \"notebooks\":\n",
    "    PROJECT_ROOT = os.path.dirname(cwd)\n",
    "else:\n",
    "    PROJECT_ROOT = cwd\n",
    "BASE = os.path.abspath('..') if os.path.basename(os.getcwd())=='notebooks' else os.path.abspath('.')\n",
    "DATA_DIR = os.path.join(BASE, 'data')\n",
    "MODELS_DIR = os.path.join(BASE, 'models')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb7d351",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "Expected columns:\n",
    "- `url`\n",
    "- optional `html_content` (raw HTML string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48c8bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>html_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cm-alliance.com/cybersecurity-blog</td>\n",
       "      <td>&lt;!doctype html&gt;&lt;!--[if lt IE 7]&gt; &lt;html class=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.varonis.com/blog/cybersecurity-tips</td>\n",
       "      <td>&lt;!doctype html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;\\n    &lt;me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               url  \\\n",
       "0   https://www.cm-alliance.com/cybersecurity-blog   \n",
       "1  https://www.varonis.com/blog/cybersecurity-tips   \n",
       "\n",
       "                                        html_content  \n",
       "0  <!doctype html><!--[if lt IE 7]> <html class=\"...  \n",
       "1  <!doctype html><html lang=\"en\"><head>\\n    <me...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(DATA_DIR, 'data.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "if 'html_content' not in df.columns:\n",
    "    df['html_content'] = ''\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "604a0e24-2901-434d-a81a-bb2e92c42799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 81\n"
     ]
    }
   ],
   "source": [
    "print('Rows:', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7c94d",
   "metadata": {},
   "source": [
    "## 3. HTML Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4546d5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>body_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cm-alliance.com/cybersecurity-blog</td>\n",
       "      <td>Cyber Security Blog</td>\n",
       "      <td>Cyber Crisis Tabletop Exercise Cyber Security ...</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.varonis.com/blog/cybersecurity-tips</td>\n",
       "      <td>Top 10 Cybersecurity Awareness Tips: How to St...</td>\n",
       "      <td>Blog Privacy &amp; Compliance Top 10 Cybersecurity...</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.cisecurity.org/insights/blog/11-cy...</td>\n",
       "      <td>11 Cyber Defense Tips to Stay Secure at Work a...</td>\n",
       "      <td>Home Insights Blog Posts 11 Cyber Defense Tips...</td>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0     https://www.cm-alliance.com/cybersecurity-blog   \n",
       "1    https://www.varonis.com/blog/cybersecurity-tips   \n",
       "2  https://www.cisecurity.org/insights/blog/11-cy...   \n",
       "\n",
       "                                               title  \\\n",
       "0                                Cyber Security Blog   \n",
       "1  Top 10 Cybersecurity Awareness Tips: How to St...   \n",
       "2  11 Cyber Defense Tips to Stay Secure at Work a...   \n",
       "\n",
       "                                           body_text  word_count  \n",
       "0  Cyber Crisis Tabletop Exercise Cyber Security ...         326  \n",
       "1  Blog Privacy & Compliance Top 10 Cybersecurity...        1747  \n",
       "2  Home Insights Blog Posts 11 Cyber Defense Tips...        1058  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_html_get_title_body(html: str):\n",
    "    if not isinstance(html, str) or not html.strip():\n",
    "        return \"\", \"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        title = soup.title.get_text(strip=True) if soup.title else \"\"\n",
    "        main = soup.find('main')\n",
    "        article = soup.find('article')\n",
    "        container = main if (main and main.get_text(strip=True)) else (article if (article and article.get_text(strip=True)) else None)\n",
    "\n",
    "        if container is None:\n",
    "            paragraphs = [p.get_text(' ', strip=True) for p in soup.find_all('p')]\n",
    "            body = \" \".join(paragraphs) if len(\" \".join(paragraphs).strip()) >= 50 else soup.get_text(' ', strip=True)\n",
    "        else:\n",
    "            body = container.get_text(' ', strip=True)\n",
    "\n",
    "        body = re.sub(r\"\\s+\", \" \", body).strip()\n",
    "        return title, body\n",
    "    except Exception:\n",
    "        return \"\", \"\"\n",
    "\n",
    "extracted_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    url = row.get('url', '')\n",
    "    html = row.get('html_content', '')\n",
    "    title, body = parse_html_get_title_body(html)\n",
    "    word_count = len(body.split()) if isinstance(body, str) else 0\n",
    "    extracted_rows.append({'url': url, 'title': title, 'body_text': body, 'word_count': word_count})\n",
    "extracted_df = pd.DataFrame(extracted_rows)\n",
    "extracted_df.to_csv(os.path.join(DATA_DIR, 'extracted_content.csv'), index=False)\n",
    "extracted_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502b3f1",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9914b846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>top_keywords</th>\n",
       "      <th>embedding</th>\n",
       "      <th>is_thin</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cm-alliance.com/cybersecurity-blog</td>\n",
       "      <td>326</td>\n",
       "      <td>7</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>cyber|cybersecurity|training|events|clients</td>\n",
       "      <td>[0.1457109878739277, 0.17160831109043065, -0.1...</td>\n",
       "      <td>True</td>\n",
       "      <td>Cyber Security Blog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.varonis.com/blog/cybersecurity-tips</td>\n",
       "      <td>1747</td>\n",
       "      <td>94</td>\n",
       "      <td>44.244681</td>\n",
       "      <td>varonis|data|access|security|cybersecurity</td>\n",
       "      <td>[0.28637120593334014, 0.40330652914180265, -0....</td>\n",
       "      <td>False</td>\n",
       "      <td>Top 10 Cybersecurity Awareness Tips: How to St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.cisecurity.org/insights/blog/11-cy...</td>\n",
       "      <td>1058</td>\n",
       "      <td>72</td>\n",
       "      <td>55.916667</td>\n",
       "      <td>password|cyber defense|don|authentication|cyber</td>\n",
       "      <td>[0.23657454565026703, 0.3298751839786317, -0.1...</td>\n",
       "      <td>False</td>\n",
       "      <td>11 Cyber Defense Tips to Stay Secure at Work a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  word_count  \\\n",
       "0     https://www.cm-alliance.com/cybersecurity-blog         326   \n",
       "1    https://www.varonis.com/blog/cybersecurity-tips        1747   \n",
       "2  https://www.cisecurity.org/insights/blog/11-cy...        1058   \n",
       "\n",
       "   sentence_count  flesch_reading_ease  \\\n",
       "0               7            10.000000   \n",
       "1              94            44.244681   \n",
       "2              72            55.916667   \n",
       "\n",
       "                                      top_keywords  \\\n",
       "0      cyber|cybersecurity|training|events|clients   \n",
       "1       varonis|data|access|security|cybersecurity   \n",
       "2  password|cyber defense|don|authentication|cyber   \n",
       "\n",
       "                                           embedding  is_thin  \\\n",
       "0  [0.1457109878739277, 0.17160831109043065, -0.1...     True   \n",
       "1  [0.28637120593334014, 0.40330652914180265, -0....    False   \n",
       "2  [0.23657454565026703, 0.3298751839786317, -0.1...    False   \n",
       "\n",
       "                                               title  \n",
       "0                                Cyber Security Blog  \n",
       "1  Top 10 Cybersecurity Awareness Tips: How to St...  \n",
       "2  11 Cyber Defense Tips to Stay Secure at Work a...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def sentence_count(text: str) -> int:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return 0\n",
    "    parts = re.split(r\"[.!?]+(?:\\s|$)\", text)\n",
    "    parts = [p for p in parts if p.strip()]\n",
    "    return len(parts)\n",
    "\n",
    "extracted_df['clean_text'] = extracted_df['body_text'].apply(clean_text)\n",
    "extracted_df['sentence_count'] = extracted_df['body_text'].apply(sentence_count)\n",
    "\n",
    "def safe_flesch(text: str) -> float:\n",
    "    if textstat:\n",
    "        try:\n",
    "            return float(textstat.flesch_reading_ease(text)) if isinstance(text, str) and text.strip() else 0.0\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Fallback proxy\n",
    "    wc = len(text.split()) if isinstance(text, str) else 0\n",
    "    sc = sentence_count(text)\n",
    "    if wc == 0 or sc == 0:\n",
    "        return 0.0\n",
    "    avg_sentence_len = wc / max(sc, 1)\n",
    "    score = max(0.0, 100.0 - min(90.0, avg_sentence_len * 3.0))\n",
    "    return score\n",
    "\n",
    "extracted_df['flesch_reading_ease'] = extracted_df['body_text'].apply(safe_flesch)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(extracted_df['clean_text'].fillna(''))\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "\n",
    "top_keywords = []\n",
    "for i in range(X_tfidf.shape[0]):\n",
    "    row = X_tfidf.getrow(i)\n",
    "    if row.nnz == 0:\n",
    "        top_keywords.append(\"\")\n",
    "        continue\n",
    "    idx_sorted = np.argsort(row.data)[::-1][:5]\n",
    "    terms = feature_names[row.indices[idx_sorted]]\n",
    "    top_keywords.append(\"|\".join(terms))\n",
    "\n",
    "extracted_df['top_keywords'] = top_keywords\n",
    "\n",
    "svd = TruncatedSVD(n_components=min(50, max(1, X_tfidf.shape[1]//2 or 1)), random_state=42)\n",
    "X_svd = svd.fit_transform(X_tfidf)\n",
    "extracted_df['embedding'] = [json.dumps(v.tolist()) for v in X_svd]\n",
    "\n",
    "extracted_df['is_thin'] = extracted_df['word_count'] < 500\n",
    "\n",
    "features_cols = ['url','word_count','sentence_count','flesch_reading_ease','top_keywords','embedding','is_thin','title']\n",
    "features_df = extracted_df[features_cols].copy()\n",
    "features_df.to_csv(os.path.join(DATA_DIR, 'features.csv'), index=False)\n",
    "features_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13519c02",
   "metadata": {},
   "source": [
    "## 5. Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e3193c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages analyzed: 81\n",
      "Duplicate pairs: 28\n",
      "Thin content pages: 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url1</th>\n",
       "      <th>url2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://nordlayer.com/learn/network-security/b...</td>\n",
       "      <td>https://www.fortinet.com/resources/cyberglossa...</td>\n",
       "      <td>0.9558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://nordlayer.com/learn/network-security/b...</td>\n",
       "      <td>https://www.cisco.com/site/us/en/learn/topics/...</td>\n",
       "      <td>0.8279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.fortinet.com/resources/cyberglossa...</td>\n",
       "      <td>https://www.trendmicro.com/en_us/what-is/netwo...</td>\n",
       "      <td>0.8757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://guardiandigital.com/resources/blog/gui...</td>\n",
       "      <td>https://inspiredelearning.com/blog/phishing-pr...</td>\n",
       "      <td>0.9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://en.wikipedia.org/wiki/SD-WAN</td>\n",
       "      <td>https://www.cisco.com/site/us/en/learn/topics/...</td>\n",
       "      <td>0.9589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                url1  \\\n",
       "0  https://nordlayer.com/learn/network-security/b...   \n",
       "1  https://nordlayer.com/learn/network-security/b...   \n",
       "2  https://www.fortinet.com/resources/cyberglossa...   \n",
       "3  https://guardiandigital.com/resources/blog/gui...   \n",
       "4               https://en.wikipedia.org/wiki/SD-WAN   \n",
       "\n",
       "                                                url2  similarity  \n",
       "0  https://www.fortinet.com/resources/cyberglossa...      0.9558  \n",
       "1  https://www.cisco.com/site/us/en/learn/topics/...      0.8279  \n",
       "2  https://www.trendmicro.com/en_us/what-is/netwo...      0.8757  \n",
       "3  https://inspiredelearning.com/blog/phishing-pr...      0.9737  \n",
       "4  https://www.cisco.com/site/us/en/learn/topics/...      0.9589  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix = cosine_similarity(X_svd)\n",
    "threshold = 0.80\n",
    "pairs = []\n",
    "n = sim_matrix.shape[0]\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        sim = float(sim_matrix[i, j])\n",
    "        if sim >= threshold:\n",
    "            pairs.append({'url1': extracted_df.loc[i, 'url'],\n",
    "                          'url2': extracted_df.loc[j, 'url'],\n",
    "                          'similarity': round(sim, 4)})\n",
    "dupes_df = pd.DataFrame(pairs)\n",
    "dupes_df.to_csv(os.path.join(DATA_DIR, 'duplicates.csv'), index=False)\n",
    "print('Total pages analyzed:', n)\n",
    "print('Duplicate pairs:', len(dupes_df))\n",
    "print('Thin content pages:', int(extracted_df['is_thin'].sum()))\n",
    "dupes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a188ccd",
   "metadata": {},
   "source": [
    "## 6. Quality Labels & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b278079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.86      1.00      0.92        12\n",
      "      Medium       1.00      0.67      0.80         9\n",
      "        High       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.88        25\n",
      "   macro avg       0.89      0.89      0.87        25\n",
      "weighted avg       0.90      0.88      0.87        25\n",
      "\n",
      "Overall Accuracy: 0.88\n",
      "Baseline Accuracy: 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Gauth\\\\models\\\\quality_model.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_quality(row):\n",
    "    wc = row['word_count']\n",
    "    re_ = row['flesch_reading_ease']\n",
    "    if (wc > 1500) and (50 <= re_ <= 70):\n",
    "        return 'High'\n",
    "    if (wc < 500) or (re_ < 30):\n",
    "        return 'Low'\n",
    "    return 'Medium'\n",
    "\n",
    "features_df['quality_label'] = features_df.apply(label_quality, axis=1)\n",
    "\n",
    "num_cols = ['word_count','sentence_count','flesch_reading_ease']\n",
    "X = extracted_df[num_cols].fillna(0.0)\n",
    "label_map = {'Low':0, 'Medium':1, 'High':2}\n",
    "y = features_df['quality_label'].map(label_map)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "rf = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "report = classification_report(y_test, y_pred, target_names=['Low','Medium','High'])\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "def baseline_predict(wc_series):\n",
    "    preds = []\n",
    "    for wc in wc_series:\n",
    "        if wc < 500:\n",
    "            preds.append(0)  # Low\n",
    "        elif wc > 1500:\n",
    "            preds.append(2)  # High\n",
    "        else:\n",
    "            preds.append(1)  # Medium\n",
    "    return np.array(preds)\n",
    "\n",
    "y_base_pred = baseline_predict(X_test['word_count'])\n",
    "base_acc = accuracy_score(y_test, y_base_pred)\n",
    "base_f1 = f1_score(y_test, y_base_pred, average='weighted')\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(report)\n",
    "print(\"Overall Accuracy:\", round(acc, 3))\n",
    "print(\"Baseline Accuracy:\", round(base_acc, 3))\n",
    "\n",
    "joblib.dump(rf, os.path.join(MODELS_DIR, 'quality_model.pkl')) #to save model for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a63ca4",
   "metadata": {},
   "source": [
    "## 7. Real-Time Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d840bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def analyze_url(url: str, top_k_similar: int = 5, similarity_threshold: float = 0.5):\n",
    "    # Scrape\n",
    "    html = ''\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10, headers={'User-Agent':'Mozilla/5.0'})\n",
    "        if resp.status_code == 200:\n",
    "            html = resp.text\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Parse\n",
    "    title, body = parse_html_get_title_body(html)\n",
    "    wc = len(body.split())\n",
    "    sc = sentence_count(body)\n",
    "    re_score = safe_flesch(body)\n",
    "\n",
    "    # Clean & vectorize using TF-IDF/SVD \n",
    "    text_clean = clean_text(body)\n",
    "    vec = tfidf.transform([text_clean])\n",
    "    vec_svd = svd.transform(vec)\n",
    "\n",
    "    # Similarities to corpus\n",
    "    sims = cosine_similarity(vec_svd, X_svd)[0]\n",
    "    idx_sorted = np.argsort(sims)[::-1]\n",
    "    similar_list = []\n",
    "    for idx in idx_sorted[:top_k_similar]:\n",
    "        sim = float(sims[idx])\n",
    "        if sim >= similarity_threshold:\n",
    "            similar_list.append({\n",
    "                'url': extracted_df.loc[idx, 'url'],\n",
    "                'similarity': round(sim, 4)\n",
    "            })\n",
    "\n",
    "    # Thin & label\n",
    "    is_thin = wc < 500\n",
    "    if (wc > 1500) and (50 <= re_score <= 70):\n",
    "        label = 'High'\n",
    "    elif (wc < 500) or (re_score < 30):\n",
    "        label = 'Low'\n",
    "    else:\n",
    "        label = 'Medium'\n",
    "\n",
    "    # Predict model quality class \n",
    "    model_pred = rf.predict([[wc, sc, re_score]])[0]\n",
    "    inv_map = {0:'Low',1:'Medium',2:'High'}\n",
    "    model_label = inv_map.get(int(model_pred), label)\n",
    "\n",
    "    return {\n",
    "        'url': url,\n",
    "        'title': title,\n",
    "        'word_count': wc,\n",
    "        'sentence_count': sc,\n",
    "        'readability': round(re_score, 2),\n",
    "        'is_thin': bool(is_thin),\n",
    "        'rule_label': label,\n",
    "        'model_label': model_label,\n",
    "        'similar_to': similar_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f3d53b7-ca59-47e6-9789-c4eb88d26ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"url\": \"https://www.leadwalnut.com/\",\n",
      "  \"title\": \"LeadWalnut | SEO & CRO Agency for B2B Tech Growth & Pipeline Impact\",\n",
      "  \"word_count\": 830,\n",
      "  \"sentence_count\": 43,\n",
      "  \"readability\": 42.09,\n",
      "  \"is_thin\": false,\n",
      "  \"rule_label\": \"Medium\",\n",
      "  \"model_label\": \"Medium\",\n",
      "  \"similar_to\": [\n",
      "    {\n",
      "      \"url\": \"https://www.shopify.com/blog/ecommerce-seo-beginners-guide\",\n",
      "      \"similarity\": 0.6463\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://apnews.com/hub/artificial-intelligence\",\n",
      "      \"similarity\": 0.5698\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://www.twilio.com/en-us/blog/insights/content-marketing-best-practices\",\n",
      "      \"similarity\": 0.5576\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://mailchimp.com/marketing-glossary/content-marketing/\",\n",
      "      \"similarity\": 0.5178\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://blog.hubspot.com/marketing/what-is-digital-marketing\",\n",
      "      \"similarity\": 0.5177\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Demo \n",
    "result = analyze_url('https://www.leadwalnut.com/')\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07787d9a",
   "metadata": {},
   "source": [
    "## 8. Save/Load Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96ab215c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content -> C:\\Users\\Gauth\\data\\extracted_content.csv\n",
      "Features -> C:\\Users\\Gauth\\data\\features.csv\n",
      "Duplicates -> C:\\Users\\Gauth\\data\\duplicates.csv\n",
      "Model -> C:\\Users\\Gauth\\models\\quality_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save features and duplicates \n",
    "print('Extracted content ->', os.path.join(DATA_DIR, 'extracted_content.csv'))\n",
    "print('Features ->', os.path.join(DATA_DIR, 'features.csv'))\n",
    "print('Duplicates ->', os.path.join(DATA_DIR, 'duplicates.csv'))\n",
    "print('Model ->', os.path.join(MODELS_DIR, 'quality_model.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
